{"nbformat_minor": 0, "cells": [{"execution_count": null, "cell_type": "code", "source": "import h5py, json, spacy\n\nimport numpy as np\nimport cPickle as pickle\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\n\nfrom model import LSTMModel\nfrom utils import prepare_ques_batch, prepare_im_batch, get_batches_idx", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": null, "cell_type": "code", "source": "embeddings = spacy.en.English()\nword_dim = 300\nnb_classes = 1000", "outputs": [], "metadata": {"collapsed": true, "trusted": true}}, {"execution_count": null, "cell_type": "code", "source": "h5_img_file_train = h5py.File('../data/vqa_data_img_vgg_train.h5', 'r')\nh5_img_file_test = h5py.File('../data/vqa_data_img_vgg_test.h5', 'r')\nh5_ques_file = h5py.File('../data/vqa_data_prepro.h5', 'r')\n\n\njson_file = json.load(open('data/vqa_data_prepro.json', 'r'))\nix_to_word = json_file['ix_to_word']\nix_to_ans = json_file['ix_to_ans']\n\nvocab_size = len(ix_to_word) ", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": null, "cell_type": "code", "source": "model = LSTMModel(vocab_size = vocab_size)\nmodel.build()", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": null, "cell_type": "code", "source": "max_batch_len = 26\nbatch_size = 50\nepochs = 50\ntrain_size = 82460\ntest_size = 40504", "outputs": [], "metadata": {"collapsed": true, "trusted": true}}, {"execution_count": null, "cell_type": "code", "source": "for idx in xrange(epochs):\n    batch = get_batches_idx(train_size,batch_size, True)\n    for i, train_index in batch:\n        if i%100 == 0:\n            print 'batch',i\n        ques_batch = [h5_ques_file.get('/ques_train')[t] for t in train_index]\n        ques_len_batch = [h5_ques_file.get('/ques_len_train')[t] for t in train_index]\n        ans_batch = [h5_ques_file.get('/answers')[t] for t in train_index]\n        # change the offset of answer \n        for j in xrange(len(ans_batch)):\n            ans_batch[j] = ans_batch[j] -1\n        X_ques = prepare_ques_batch(ques_batch, ques_len_batch, max_batch_len, embeddings, word_dim, ix_to_word)\n        im_ix = [h5_ques_file.get('/img_pos_train')[t] for t in train_index]\n        # change the offset of image id\n        for n in xrange(len(im_ix)):\n            im_ix[n] = im_ix[n]-1   \n        X_im = np.asarray([h5_img_file_train.get('/images_train')[single_im_ix] for single_im_ix in im_ix])\n        y = np.zeros((len(ans_batch), nb_classes))\n        y[np.arange(len(ans_batch)), ans_batch] = 1\n        loss = model.train_on_batch(X_ques, X_im, y)\n    print 'Epoch ', (idx+1), 'Loss', loss[0], 'Accurancy', loss[1]", "outputs": [], "metadata": {"scrolled": true, "collapsed": false, "trusted": true}}, {"execution_count": null, "cell_type": "code", "source": "batch = get_batches_idx(test_size,batch_size, True)\nfor _, test_index in batch:\n    ques_batch = [h5_ques_file.get('/ques_test')[t] for t in test_index]\n    ques_len_batch = [h5_ques_file.get('/ques_len_test')[t] for t in test_index]\n    ans_batch = [h5_ques_file.get('/ans_test')[t] for t in test_index]\n    for j in xrange(len(ans_batch)):\n        ans_batch[j] = ans_batch[j] -1\n    X_ques = prepare_ques_batch(ques_batch, ques_len_batch, max_batch_len, embeddings, word_dim, ix_to_word)\n    im_ix = [h5_ques_file.get('/img_pos_test')[t] for t in test_index]\n    for n in xrange(len(im_ix)):\n        im_ix[n] = im_ix[n]-1   \n    X_im = np.asarray([h5_img_file_test.get('/images_test')[single_im_ix] for single_im_ix in im_ix])\n    y = np.zeros((len(ans_batch), nb_classes))\n    y[np.arange(len(ans_batch)), [494 if a > 1000 else a for a in ans_batch]] = 1\n    loss = model.test_on_batch(X_ques, X_im, y)\nprint 'Loss', loss[0], 'Accurancy', loss[1]", "outputs": [], "metadata": {"collapsed": true, "trusted": true}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Python 2", "name": "python2", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "2.7.10", "name": "python", "file_extension": ".py", "pygments_lexer": "ipython2", "codemirror_mode": {"version": 2, "name": "ipython"}}}}