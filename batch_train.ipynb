{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import h5py, json, spacy\n",
    "\n",
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from model import LSTMModel\n",
    "from utils import prepare_ques_batch, prepare_im_batch, get_batches_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings = spacy.en.English()\n",
    "word_dim = 300\n",
    "nb_classes = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tiny dataset of 100 image features and 300 question/answer pairs for training.\n"
     ]
    }
   ],
   "source": [
    "h5_img_file_tiny = h5py.File('data/vqa_data_img_vgg_train_tiny.h5', 'r')\n",
    "fv_im_tiny = h5_img_file_tiny.get('/images_train')\n",
    "\n",
    "with open('data/qa_data_train_tiny.pkl', 'rb') as fp:\n",
    "    qa_data_tiny = pickle.load(fp)\n",
    "\n",
    "json_file = json.load(open('data/vqa_data_prepro.json', 'r'))\n",
    "ix_to_word = json_file['ix_to_word']\n",
    "ix_to_ans = json_file['ix_to_ans']\n",
    "\n",
    "vocab_size = len(ix_to_word)\n",
    "print \"Loading tiny dataset of %d image features and %d question/answer pairs for training.\" % (len(fv_im_tiny), len(qa_data_tiny)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tiny dataset of 100 image features and 300 question/answer pairs for testing\n"
     ]
    }
   ],
   "source": [
    "h5_img_file_test_tiny = h5py.File('data/vqa_data_img_vgg_test_tiny.h5', 'r')\n",
    "fv_im_test_tiny = h5_img_file_test_tiny.get('/images_test')\n",
    "\n",
    "with open('data/qa_data_test_tiny.pkl', 'rb') as fp:\n",
    "    qa_data_test_tiny = pickle.load(fp)\n",
    "    \n",
    "print \"Loading tiny dataset of %d image features and %d question/answer pairs for testing\" % (len(fv_im_test_tiny), len(qa_data_test_tiny)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "bidirectional_3 (Bidirectional)  (None, 1024)          3330048                                      \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 7, 7, 512)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)              (None, 25088)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_13 (Dense)                 (None, 4096)          102764544                                    \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_13 (BatchNorma(None, 4096)          8192                                         \n",
      "____________________________________________________________________________________________________\n",
      "dense_14 (Dense)                 (None, 4096)          16781312                                     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_14 (BatchNorma(None, 4096)          8192                                         \n",
      "____________________________________________________________________________________________________\n",
      "dense_15 (Dense)                 (None, 4096)          16781312                                     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_15 (BatchNorma(None, 4096)          8192                                         \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_16 (BatchNorma(None, 5120)          10240       merge_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_16 (Dense)                 (None, 2014)          10313694    batchnormalization_16[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_17 (BatchNorma(None, 2014)          4028        dense_16[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 2014)          0           batchnormalization_17[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dense_17 (Dense)                 (None, 2014)          4058210     dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_18 (BatchNorma(None, 2014)          4028        dense_17[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 2014)          0           batchnormalization_18[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dense_18 (Dense)                 (None, 1000)          2015000     dropout_6[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 156086992\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = LSTMModel(vocab_size = vocab_size)\n",
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_batch_len = 26\n",
    "batch_size = 50\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 Loss 7.18617 Accurancy 0.06\n",
      "Epoch  2 Loss 5.31412 Accurancy 0.2\n",
      "Epoch  3 Loss 3.30081 Accurancy 0.38\n",
      "Epoch  4 Loss 2.21071 Accurancy 0.54\n",
      "Epoch  5 Loss 1.43598 Accurancy 0.68\n",
      "Epoch  6 Loss 1.31962 Accurancy 0.66\n",
      "Epoch  7 Loss 1.02898 Accurancy 0.72\n",
      "Epoch  8 Loss 0.912009 Accurancy 0.84\n",
      "Epoch  9 Loss 0.820408 Accurancy 0.78\n",
      "Epoch  10 Loss 0.613635 Accurancy 0.82\n",
      "Epoch  11 Loss 0.565082 Accurancy 0.8\n",
      "Epoch  12 Loss 0.51537 Accurancy 0.88\n",
      "Epoch  13 Loss 0.332987 Accurancy 0.96\n",
      "Epoch  14 Loss 0.369069 Accurancy 0.92\n",
      "Epoch  15 Loss 0.610501 Accurancy 0.8\n",
      "Epoch  16 Loss 0.205189 Accurancy 0.9\n",
      "Epoch  17 Loss 0.353496 Accurancy 0.92\n",
      "Epoch  18 Loss 0.14289 Accurancy 0.94\n",
      "Epoch  19 Loss 0.406284 Accurancy 0.92\n",
      "Epoch  20 Loss 0.165164 Accurancy 0.94\n",
      "Epoch  21 Loss 0.316766 Accurancy 0.94\n",
      "Epoch  22 Loss 0.129356 Accurancy 0.94\n",
      "Epoch  23 Loss 0.285355 Accurancy 0.92\n",
      "Epoch  24 Loss 0.130115 Accurancy 0.96\n",
      "Epoch  25 Loss 0.115229 Accurancy 0.98\n",
      "Epoch  26 Loss 0.218955 Accurancy 0.96\n",
      "Epoch  27 Loss 0.35862 Accurancy 0.94\n",
      "Epoch  28 Loss 0.0894318 Accurancy 0.98\n",
      "Epoch  29 Loss 0.0284222 Accurancy 1.0\n",
      "Epoch  30 Loss 0.177361 Accurancy 0.92\n",
      "Epoch  31 Loss 0.129886 Accurancy 0.96\n",
      "Epoch  32 Loss 0.38114 Accurancy 0.9\n",
      "Epoch  33 Loss 0.118298 Accurancy 0.98\n",
      "Epoch  34 Loss 0.0800935 Accurancy 0.96\n",
      "Epoch  35 Loss 0.213118 Accurancy 0.98\n",
      "Epoch  36 Loss 0.170934 Accurancy 0.98\n",
      "Epoch  37 Loss 0.023648 Accurancy 1.0\n",
      "Epoch  38 Loss 0.0245576 Accurancy 1.0\n",
      "Epoch  39 Loss 0.0782354 Accurancy 0.98\n",
      "Epoch  40 Loss 0.0577531 Accurancy 0.98\n",
      "Epoch  41 Loss 0.0911222 Accurancy 0.98\n",
      "Epoch  42 Loss 0.137444 Accurancy 0.96\n",
      "Epoch  43 Loss 0.109089 Accurancy 0.98\n",
      "Epoch  44 Loss 0.0380165 Accurancy 1.0\n",
      "Epoch  45 Loss 0.0231862 Accurancy 1.0\n",
      "Epoch  46 Loss 0.0370848 Accurancy 0.98\n",
      "Epoch  47 Loss 0.0949248 Accurancy 0.98\n",
      "Epoch  48 Loss 0.0493134 Accurancy 0.98\n",
      "Epoch  49 Loss 0.0418431 Accurancy 0.98\n",
      "Epoch  50 Loss 0.0256754 Accurancy 1.0\n"
     ]
    }
   ],
   "source": [
    "questions, ques_len, im_ix, ans = zip(*qa_data_tiny)\n",
    "\n",
    "for idx in xrange(epochs):\n",
    "    batch = get_batches_idx(300,batch_size, True)\n",
    "    for _, train_index in batch:\n",
    "        uidx += 1\n",
    "        n_samples += len(batch)\n",
    "        ques_batch = [questions[t] for t in train_index]\n",
    "        ques_len_batch = [ques_len[t] for t in train_index]\n",
    "        img_batch = [im_ix[t] for t in train_index]\n",
    "        ans_batch = [ans[t] for t in train_index]\n",
    "        X_ques = prepare_ques_batch(ques_batch, ques_len_batch, max_batch_len, embeddings, word_dim, ix_to_word)\n",
    "        X_im = prepare_im_batch(fv_im_tiny, img_batch)\n",
    "        y = np.zeros((len(ans_batch), nb_classes))\n",
    "        y[np.arange(len(ans_batch)), ans_batch] = 1\n",
    "        loss = model.train_on_batch(X_ques, X_im, y)\n",
    "    print 'Epoch ', (idx+1), 'Loss', loss[0], 'Accurancy', loss[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "questions, ques_len, im_ix, ans = zip(*qa_data_test_tiny)\n",
    "\n",
    "X_ques_test = prepare_ques_batch(questions, ques_len, max_ques_len, embeddings, word_dim, ix_to_word)\n",
    "X_im_test = prepare_im_batch(fv_im_test_tiny, im_ix)\n",
    "y_test = np.zeros((len(ans), nb_classes))\n",
    "y_test[np.arange(len(ans)), [494 if a > 1000 else a for a in ans]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 4s     \n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_ques_test, X_im_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n"
     ]
    }
   ],
   "source": [
    "print acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
