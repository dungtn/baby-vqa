{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import h5py, json, spacy\n",
    "\n",
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from model import LSTMModel\n",
    "from utils import prepare_ques_batch, prepare_im_batch, get_batches_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings = spacy.en.English()\n",
    "word_dim = 300\n",
    "nb_classes = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h5_img_file_train = h5py.File('../data/vqa_data_img_vgg_train.h5', 'r')\n",
    "h5_img_file_test = h5py.File('../data/vqa_data_img_vgg_test.h5', 'r')\n",
    "h5_ques_file = h5py.File('../data/vqa_data_prepro.h5', 'r')\n",
    "\n",
    "\n",
    "json_file = json.load(open('data/vqa_data_prepro.json', 'r'))\n",
    "ix_to_word = json_file['ix_to_word']\n",
    "ix_to_ans = json_file['ix_to_ans']\n",
    "\n",
    "vocab_size = len(ix_to_word) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = LSTMModel(vocab_size = vocab_size)\n",
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_batch_len = 26\n",
    "batch_size = 500\n",
    "epochs = 50\n",
    "train_size = 82460\n",
    "test_size = 40504"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx in xrange(epochs):\n",
    "    batch = get_batches_idx(train_size,batch_size, True)\n",
    "    for i, train_index in batch:\n",
    "        print 'Batch', i\n",
    "        ques_batch = [h5_ques_file.get('/ques_train')[t] for t in train_index]\n",
    "        ques_len_batch = [h5_ques_file.get('/ques_len_train')[t] for t in train_index]\n",
    "        ans_batch = [h5_ques_file.get('/answers')[t] for t in train_index]\n",
    "        X_ques = prepare_ques_batch(ques_batch, ques_len_batch, max_batch_len, embeddings, word_dim, ix_to_word)\n",
    "        im_ix = [h5_ques_file.get('/img_pos_train')[t] for t in train_index]\n",
    "        X_im = np.asarray([h5_img_file_train.get('/images_train')[single_im_ix] for single_im_ix in im_ix])\n",
    "        y = np.zeros((len(ans_batch), nb_classes))\n",
    "        y[np.arange(len(ans_batch)), ans_batch] = 1\n",
    "        loss = model.train_on_batch(X_ques, X_im, y)\n",
    "    print 'Epoch ', (idx+1), 'Loss', loss[0], 'Accurancy', loss[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch = get_batches_idx(test_size,batch_size, True)\n",
    "\n",
    "for _, test_index in batch:\n",
    "    ques_batch = [h5_ques_file.get('/ques_test')[t] for t in test_index]\n",
    "    ques_len_batch = [h5_ques_file.get('/ques_len_test')[t] for t in test_index]\n",
    "    ans_batch = [h5_ques_file.get('/ans_test')[t] for t in test_index]\n",
    "    X_ques = prepare_ques_batch(ques_batch, ques_len_batch, max_batch_len, embeddings, word_dim, ix_to_word)\n",
    "    im_ix = [h5_ques_file.get('/img_pos_test')[t] for t in test_index]\n",
    "    X_im = np.asarray([h5_img_file_test.get('/images_test')[single_im_ix] for single_im_ix in im_ix])\n",
    "    y = np.zeros((len(ans_batch), nb_classes))\n",
    "    y[np.arange(len(ans_batch)), [494 if a > 1000 else a for a in ans_batch]] = 1\n",
    "    loss = model.test_on_batch(X_ques, X_im, y)\n",
    "print 'Epoch ', (idx+1), 'Loss', loss[0], 'Accurancy', loss[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(X_ques_test, X_im_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
